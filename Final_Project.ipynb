{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "interested-worker",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-spine",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "sharing-zealand",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    \"\"\"\n",
    "    Load Dataset from File\n",
    "    \"\"\"\n",
    "    input_file = os.path.join(path)\n",
    "    with open(input_file, \"r\") as f:\n",
    "        data = f.read()\n",
    "\n",
    "    return data\n",
    "\n",
    "def preprocess_and_save_data(dataset_path, token_lookup, create_lookup_tables):\n",
    "    \"\"\"\n",
    "    Preprocess Text Data\n",
    "    \"\"\"\n",
    "    text = load_data(dataset_path)\n",
    "    \n",
    "    # Ignore notice, since we don't use it for analysing the data\n",
    "    text = text[81:]\n",
    "\n",
    "    token_dict = token_lookup()\n",
    "    for key, token in token_dict.items():\n",
    "        text = text.replace(key, ' {} '.format(token))\n",
    "\n",
    "    text = text.lower()\n",
    "    text = text.split()\n",
    "\n",
    "    vocab_to_int, int_to_vocab = create_lookup_tables(text + list(SPECIAL_WORDS.values()))\n",
    "    int_text = [vocab_to_int[word] for word in text]\n",
    "    pickle.dump((int_text, vocab_to_int, int_to_vocab, token_dict), open('preprocess.p', 'wb'))\n",
    "\n",
    "def load_preprocess():\n",
    "    \"\"\"\n",
    "    Load the Preprocessed Training data and return them in batches of <batch_size> or less\n",
    "    \"\"\"\n",
    "    return pickle.load(open('preprocess.p', mode='rb'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "contrary-certification",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Character</th>\n",
       "      <th>Dialogue</th>\n",
       "      <th>EpisodeNo</th>\n",
       "      <th>SEID</th>\n",
       "      <th>Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JERRY</td>\n",
       "      <td>Do you know what this is all about? Do you kno...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>S01E01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JERRY</td>\n",
       "      <td>(pointing at Georges shirt) See, to me, that b...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>S01E01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GEORGE</td>\n",
       "      <td>Are you through?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>S01E01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JERRY</td>\n",
       "      <td>You do of course try on, when you buy?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>S01E01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GEORGE</td>\n",
       "      <td>Yes, it was purple, I liked it, I dont actuall...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>S01E01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Character                                           Dialogue  EpisodeNo  \\\n",
       "0     JERRY  Do you know what this is all about? Do you kno...        1.0   \n",
       "1     JERRY  (pointing at Georges shirt) See, to me, that b...        1.0   \n",
       "2    GEORGE                                   Are you through?        1.0   \n",
       "3     JERRY             You do of course try on, when you buy?        1.0   \n",
       "4    GEORGE  Yes, it was purple, I liked it, I dont actuall...        1.0   \n",
       "\n",
       "     SEID  Season  \n",
       "0  S01E01     1.0  \n",
       "1  S01E01     1.0  \n",
       "2  S01E01     1.0  \n",
       "3  S01E01     1.0  \n",
       "4  S01E01     1.0  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scripts = pd.read_csv('./data/scripts.csv', index_col=0)\n",
    "scripts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "national-shell",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dialogue</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Character</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>JERRY</th>\n",
       "      <td>14786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GEORGE</th>\n",
       "      <td>9708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELAINE</th>\n",
       "      <td>7983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KRAMER</th>\n",
       "      <td>6664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEWMAN</th>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MORTY</th>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HELEN</th>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FRANK</th>\n",
       "      <td>436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SUSAN</th>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[Setting</th>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Dialogue\n",
       "Character          \n",
       "JERRY         14786\n",
       "GEORGE         9708\n",
       "ELAINE         7983\n",
       "KRAMER         6664\n",
       "NEWMAN          640\n",
       "MORTY           505\n",
       "HELEN           471\n",
       "FRANK           436\n",
       "SUSAN           379\n",
       "[Setting        293"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scripts[['Character', 'Dialogue']].groupby(['Character']).count().sort_values(by='Dialogue',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toxic-calcium",
   "metadata": {},
   "source": [
    "**The main characters are JERRY(has 14786 dialogues), GEORGE(9708 dialogues), ELAINE(7983 dialogues) and KRAMER(6664 dialogues). One can see that the rest character has 10x less dialogues afterwards. To maintain the characteristics of each role, we will train the RNN model for each of them respectively.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "abstract-graphics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_role_dialogue(r):\n",
    "    return r[0].lower()+\": \"+ r[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "wicked-lithuania",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Character</th>\n",
       "      <th>Dialogue</th>\n",
       "      <th>EpisodeNo</th>\n",
       "      <th>SEID</th>\n",
       "      <th>Season</th>\n",
       "      <th>char_dial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JERRY</td>\n",
       "      <td>Do you know what this is all about? Do you kno...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>S01E01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>jerry: Do you know what this is all about? Do ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JERRY</td>\n",
       "      <td>(pointing at Georges shirt) See, to me, that b...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>S01E01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>jerry: (pointing at Georges shirt) See, to me,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GEORGE</td>\n",
       "      <td>Are you through?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>S01E01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>george: Are you through?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JERRY</td>\n",
       "      <td>You do of course try on, when you buy?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>S01E01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>jerry: You do of course try on, when you buy?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GEORGE</td>\n",
       "      <td>Yes, it was purple, I liked it, I dont actuall...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>S01E01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>george: Yes, it was purple, I liked it, I dont...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Character                                           Dialogue  EpisodeNo  \\\n",
       "0     JERRY  Do you know what this is all about? Do you kno...        1.0   \n",
       "1     JERRY  (pointing at Georges shirt) See, to me, that b...        1.0   \n",
       "2    GEORGE                                   Are you through?        1.0   \n",
       "3     JERRY             You do of course try on, when you buy?        1.0   \n",
       "4    GEORGE  Yes, it was purple, I liked it, I dont actuall...        1.0   \n",
       "\n",
       "     SEID  Season                                          char_dial  \n",
       "0  S01E01     1.0  jerry: Do you know what this is all about? Do ...  \n",
       "1  S01E01     1.0  jerry: (pointing at Georges shirt) See, to me,...  \n",
       "2  S01E01     1.0                           george: Are you through?  \n",
       "3  S01E01     1.0      jerry: You do of course try on, when you buy?  \n",
       "4  S01E01     1.0  george: Yes, it was purple, I liked it, I dont...  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scripts['char_dial'] = scripts[['Character', 'Dialogue']].apply(convert_to_role_dialogue)\n",
    "scripts['char_dial'] = scripts['Character'].str.lower()+': '+scripts['Dialogue']\n",
    "scripts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "passing-specification",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scripts[['char_dial']].to_csv(r'./data/test.txt', header=None, index=None, sep='\\n', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "divided-refund",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Character                                           Dialogue  EpisodeNo  \\\n",
      "0     JERRY  Do you know what this is all about? Do you kno...        1.0   \n",
      "1     JERRY  (pointing at Georges shirt) See, to me, that b...        1.0   \n",
      "3     JERRY             You do of course try on, when you buy?        1.0   \n",
      "5     JERRY                               Oh, you dont recall?        1.0   \n",
      "7     JERRY  Well, senator, Id just like to know, what you ...        1.0   \n",
      "\n",
      "     SEID  Season                                          char_dial  \n",
      "0  S01E01     1.0  jerry: Do you know what this is all about? Do ...  \n",
      "1  S01E01     1.0  jerry: (pointing at Georges shirt) See, to me,...  \n",
      "3  S01E01     1.0      jerry: You do of course try on, when you buy?  \n",
      "5  S01E01     1.0                        jerry: Oh, you dont recall?  \n",
      "7  S01E01     1.0  jerry: Well, senator, Id just like to know, wh...  \n",
      "   Character                                           Dialogue  EpisodeNo  \\\n",
      "2     GEORGE                                   Are you through?        1.0   \n",
      "4     GEORGE  Yes, it was purple, I liked it, I dont actuall...        1.0   \n",
      "6     GEORGE  (on an imaginary microphone) Uh, no, not at th...        1.0   \n",
      "9     GEORGE  Are, are you sure this is decaf? Wheres the or...        1.0   \n",
      "13    GEORGE  How come youre not doin the second show tomorrow?        1.0   \n",
      "\n",
      "      SEID  Season                                          char_dial  \n",
      "2   S01E01     1.0                           george: Are you through?  \n",
      "4   S01E01     1.0  george: Yes, it was purple, I liked it, I dont...  \n",
      "6   S01E01     1.0  george: (on an imaginary microphone) Uh, no, n...  \n",
      "9   S01E01     1.0  george: Are, are you sure this is decaf? Where...  \n",
      "13  S01E01     1.0  george: How come youre not doin the second sho...  \n",
      "    Character                                           Dialogue  EpisodeNo  \\\n",
      "215    ELAINE  Coccoon II The Return. I guess they didnt like...        1.0   \n",
      "217    ELAINE  Okay, whatre we doing here? I have seen everyt...        1.0   \n",
      "219    ELAINE                                        Oh, lovely.        1.0   \n",
      "221    ELAINE             What do you think their parents think?        1.0   \n",
      "223    ELAINE  Yknow what? This would be a really funny gift ...        1.0   \n",
      "\n",
      "       SEID  Season                                          char_dial  \n",
      "215  S01E01     1.0  elaine: Coccoon II The Return. I guess they di...  \n",
      "217  S01E01     1.0  elaine: Okay, whatre we doing here? I have see...  \n",
      "219  S01E01     1.0                                elaine: Oh, lovely.  \n",
      "221  S01E01     1.0     elaine: What do you think their parents think?  \n",
      "223  S01E01     1.0  elaine: Yknow what? This would be a really fun...  \n",
      "    Character                                           Dialogue  EpisodeNo  \\\n",
      "144    KRAMER  Do you handle any of that commercial...real es...        1.0   \n",
      "458    KRAMER                                                Hi.        1.0   \n",
      "461    KRAMER              Hey Morty! (to Jerry) Salad dressing?        1.0   \n",
      "467    KRAMER                             Quo? Thats not a word.        1.0   \n",
      "491    KRAMER  No, you dont have to challenge that. Thats a w...        1.0   \n",
      "\n",
      "       SEID  Season                                          char_dial  \n",
      "144  S01E01     1.0  kramer: Do you handle any of that commercial.....  \n",
      "458  S01E01     1.0                                        kramer: Hi.  \n",
      "461  S01E01     1.0      kramer: Hey Morty! (to Jerry) Salad dressing?  \n",
      "467  S01E01     1.0                     kramer: Quo? Thats not a word.  \n",
      "491  S01E01     1.0  kramer: No, you dont have to challenge that. T...  \n"
     ]
    }
   ],
   "source": [
    "for i in ['jerry', 'george', 'elaine', 'kramer']:\n",
    "    temp = scripts[scripts.Character == i.upper()]\n",
    "    print(temp.head())\n",
    "    temp[['char_dial']].to_csv(r'./data/{i}_script.txt'.format(i=i), header=None, index=None, sep='\\n', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "sonic-request",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/jerry_script.txt\n"
     ]
    }
   ],
   "source": [
    "data_dir = './data/{i}_script.txt'.format(i='jerry')\n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "biological-february",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Stats\n",
      "Roughly the number of unique words: 46367\n",
      "Number of lines: 109233\n",
      "Average number of words in each line: 5.544240293684143\n",
      "\n",
      "The lines 30 to 50:\n",
      "george: wait a second, wait a second, what coming in, what woman is coming in? \n",
      "\n",
      "jerry: i told you about laura, the girl i met in michigan? \n",
      "\n",
      "george: no, you didnt! \n",
      "\n",
      "jerry: i thought i told you about it, yes, she teaches political science? i met her the night i did the show in lansing... \n",
      "\n",
      "george: ha. \n",
      "\n",
      "jerry: (looks in the creamer) theres no milk in here, what... \n",
      "\n",
      "george: wait wait wait, what is she... (takes the milk can from jerry and puts it on the table) what is she like? \n",
      "\n",
      "jerry: oh, shes really great. i mean, shes got like a real warmth about her and shes really bright and really pretty and uh... the conversation though, i mean, it was... talking with her is like talking with you, but, you know, obviously much better. \n",
      "\n",
      "george: (smiling) so, you know, what, what happened? \n",
      "\n",
      "jerry: oh, nothing happened, you know, but is was great. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "view_line_range = (30, 50)\n",
    "\n",
    "print('Dataset Stats')\n",
    "print('Roughly the number of unique words: {}'.format(len({word: None for word in text.split()})))\n",
    "\n",
    "lines = text.split('\\n')\n",
    "print('Number of lines: {}'.format(len(lines)))\n",
    "word_count_line = [len(line.split()) for line in lines]\n",
    "print('Average number of words in each line: {}'.format(np.average(word_count_line)))\n",
    "\n",
    "print()\n",
    "print('The lines {} to {}:'.format(*view_line_range))\n",
    "print('\\n'.join(text.split('\\n')[view_line_range[0]:view_line_range[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cardiac-first",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lookup_tables(text):\n",
    "    \"\"\"\n",
    "    Create lookup tables for vocabulary\n",
    "    :param text: The text of tv scripts split into words\n",
    "    :return: A tuple of dicts (vocab_to_int, int_to_vocab)\n",
    "    \"\"\"\n",
    "    chars = sorted(list(set(text))) # getting all unique chars\n",
    "    print('total chars: ', len(chars))\n",
    "    char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "    indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "    return chars, (char_indices, indices_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "activated-wesley",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_lookup():\n",
    "    \"\"\"\n",
    "    Generate a dict to turn punctuation into a token.\n",
    "    :return: Tokenized dictionary where the key is the punctuation and the value is the token\n",
    "    \"\"\"\n",
    "    return {\n",
    "        '.': '||Period||',\n",
    "        ',': '||Comma||',\n",
    "        '\"': '||Quotation_Mark||',\n",
    "        ';': '||Semicolon||',\n",
    "        '!': '||Exclamation_Mark||',\n",
    "        '?': '||Question_Mark||',\n",
    "        '(': '||Left_Parentheses||',\n",
    "        ')': '||Right_Parentheses||',\n",
    "        '-': '||Dash||',\n",
    "        '\\n': '||Return||'\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "played-conclusion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars:  9923\n"
     ]
    }
   ],
   "source": [
    "SPECIAL_WORDS = {'PADDING': '<PAD>'}\n",
    "preprocess_and_save_data(data_dir, token_lookup, create_lookup_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "personalized-investment",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = load_data(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "manufactured-oxide",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = sorted(list(set(text)))\n",
    "char_to_indices = dict((c, i) for i, c in enumerate(vocabulary))\n",
    "indices_to_char = dict((i, c) for i, c in enumerate(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "turned-cargo",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 20\n",
    "steps = 5\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - max_length, steps):\n",
    "    sentences.append(text[i: i + max_length])\n",
    "    next_chars.append(text[i + max_length])\n",
    "      \n",
    "# Hot encoding each character into a boolean vector\n",
    "  \n",
    "# Initializing a matrix of boolean vectors with each column representing\n",
    "# the hot encoded representation of the character\n",
    "X = np.zeros((len(sentences), max_length, len(vocabulary)), dtype = np.bool)\n",
    "y = np.zeros((len(sentences), len(vocabulary)), dtype = np.bool)\n",
    "  \n",
    "# Placing the value 1 at the appropriate position for each vector\n",
    "# to complete the hot-encoding process\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_to_indices[char]] = 1\n",
    "        y[i, char_to_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-irish",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "destroyed-bundle",
   "metadata": {},
   "source": [
    "## Build GRU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "premium-guatemala",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "  \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "  \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM,GRU\n",
    "  \n",
    "from keras.optimizers import RMSprop\n",
    "  \n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "egyptian-carol",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the LSTM network\n",
    "model = Sequential()\n",
    "  \n",
    "# Defining the cell type\n",
    "model.add(GRU(128, input_shape =(max_length, len(vocabulary))))\n",
    "  \n",
    "# Defining the densely connected Neural Network layer\n",
    "model.add(Dense(len(vocabulary)))\n",
    "  \n",
    "# Defining the activation function for the cell\n",
    "model.add(Activation('softmax'))\n",
    "  \n",
    "# Defining the optimizing function\n",
    "optimizer = RMSprop(lr = 0.01)\n",
    "  \n",
    "# Configuring the model for training\n",
    "model.compile(loss ='categorical_crossentropy', optimizer = optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-collector",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-4.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
